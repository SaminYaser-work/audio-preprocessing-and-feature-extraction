{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import data_loader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## Yamnet imports \n",
    "import params as yamnet_params\n",
    "import yamnet_modified  as yamnet_model\n",
    "import features as features_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yamnet_params.Params()\n",
    "\n",
    "class_names = yamnet_model.class_names(\n",
    "    './yamnet_class_map.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data_loader(\n",
    "    Crema_path='../../Datasets/Crema/',\n",
    "    Ravdess_path='../../Datasets/Ravdess/',\n",
    "    Savee_path='../../Datasets/Savee/',\n",
    "    Tess_path='../../Datasets/Tess/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [03:49<00:00, 12.19it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = dl.get_numpy('tess', pad=True, max_len=40_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, val_data, val_label, test_data, test_label = dl.split_numpy(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder, train_label, val_label, test_label = dl.ohe_labels(train_label, val_label, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1960, 40000), (1960,), (420, 40000), (420,), (420, 40000), (420,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_label.shape, val_data.shape, val_label.shape, test_data.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.tolist()\n",
    "# train_label = train_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_data, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices((train_data, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(40000,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.string, name=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(40000,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.string, name=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(40000,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.string, name=None))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function recived the wav file and each wav file divid to frames with \n",
    "#96ms longe and 10ms hope.for each frame the lable is the label of the\n",
    "#main audio file.Then a batch of these frames is used as input to the yamnet model\n",
    "# def yamnet_frames_model_transfer1(wav_data):\n",
    "#     waveform_padded = features_lib.pad_waveform(wav_data, params)\n",
    "#     log_mel_spectrogram, features = features_lib.waveform_to_log_mel_spectrogram_patches(\n",
    "#         waveform_padded, params)\n",
    "#     # num_embeddings = tf.shape(features)[0]\n",
    "#     return log_mel_spectrogram\n",
    "\n",
    "def yamnet_frames_model_transfer1(wav_data, class_names):\n",
    "    waveform_padded = features_lib.pad_waveform(wav_data, params)\n",
    "    log_mel_spectrogram, features = features_lib.waveform_to_log_mel_spectrogram_patches(\n",
    "        waveform_padded, params)\n",
    "    return log_mel_spectrogram, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(yamnet_frames_model_transfer1)\n",
    "val_ds = val_ds.map(yamnet_frames_model_transfer1)\n",
    "test_ds = test_ds.map(yamnet_frames_model_transfer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(288, 64), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "(TensorSpec(shape=(288, 64), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      "(TensorSpec(shape=(288, 64), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.element_spec)\n",
    "print(val_ds.element_spec)\n",
    "print(test_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_mod = [yamnet_frames_model_transfer1(train_data[i]) for i in tqdm(range(len(train_data)))]\n",
    "# val_data_mod = [yamnet_frames_model_transfer1(val_data[i]) for i in tqdm(range(len(val_data)))]\n",
    "# test_data_mod = [yamnet_frames_model_transfer1(test_data[i]) for i in tqdm(range(len(test_data)))]\n",
    "\n",
    "# train_data_mod = np.array(train_data_mod)\n",
    "# val_data_mod = np.array(val_data_mod)\n",
    "# test_data_mod = np.array(test_data_mod)\n",
    "\n",
    "# train_data_mod.shape, val_data_mod.shape, test_data_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_mod = tf.convert_to_tensor(train_data_mod)\n",
    "# val_data_mod = tf.convert_to_tensor(val_data_mod)\n",
    "# test_data_mod = tf.convert_to_tensor(test_data_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_mod = tf.expand_dims(train_data_mod, axis=-1)\n",
    "# val_data_mod = tf.expand_dims(val_data_mod, axis=-1)\n",
    "# test_data_mod = tf.expand_dims(test_data_mod, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_mod.shape, val_data_mod.shape, test_data_mod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load yamnet model. yamnet_frames_model_transfer1 is modified version of the\n",
    "#yamnet_frames_model_transfer in yamnet.py file in order to be able the \n",
    "#train yamnet from scratch\n",
    "\n",
    "classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "yamnet = yamnet_model.yamnet_frames_model_transfer(params, len(classes))\n",
    "\n",
    "preloaded_layers = yamnet.layers.copy()\n",
    "preloaded_weights = []\n",
    "\n",
    "for pre in preloaded_layers:\n",
    "        preloaded_weights.append(pre.get_weights())    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2443: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a1, a2 = asarray(a1), asarray(a2)\n"
     ]
    }
   ],
   "source": [
    "#load the weights from pretrain model except for the last layer and\n",
    "#check which layer used the pretrain weights\n",
    "# store weights before loading pre-trained weights\n",
    "\n",
    "chkp=True\n",
    "\n",
    "if chkp==True:\n",
    "# load pre-trained weights(fine tuning the model)\n",
    "#load the weights from pretrain model except for the last layer\n",
    "    yamnet.load_weights('./yamnet.h5',by_name=True)\n",
    " #   yamnet.load_weights('D:/bat_n/yamnet_2.h5',by_name=True)\n",
    "    for layer, pre in zip(yamnet.layers, preloaded_weights):\n",
    "        weights = layer.get_weights()\n",
    "        if weights:\n",
    "            if np.array_equal(weights, pre):\n",
    "                print('not loaded', layer.name)\n",
    "            # else:\n",
    "            #     print('loaded', layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yamnet_frames\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 96, 64, 1)         0         \n",
      "                                                                 \n",
      " layer1/conv (Conv2D)        (None, 48, 32, 32)        288       \n",
      "                                                                 \n",
      " layer1/conv/bn (BatchNormal  (None, 48, 32, 32)       96        \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " layer1/relu (ReLU)          (None, 48, 32, 32)        0         \n",
      "                                                                 \n",
      " layer2/depthwise_conv (Dept  (None, 48, 32, 32)       288       \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer2/depthwise_conv/bn (B  (None, 48, 32, 32)       96        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer2/depthwise_conv/relu   (None, 48, 32, 32)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer2/pointwise_conv (Conv  (None, 48, 32, 64)       2048      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer2/pointwise_conv/bn (B  (None, 48, 32, 64)       192       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer2/pointwise_conv/relu   (None, 48, 32, 64)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer3/depthwise_conv (Dept  (None, 24, 16, 64)       576       \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer3/depthwise_conv/bn (B  (None, 24, 16, 64)       192       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer3/depthwise_conv/relu   (None, 24, 16, 64)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer3/pointwise_conv (Conv  (None, 24, 16, 128)      8192      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer3/pointwise_conv/bn (B  (None, 24, 16, 128)      384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer3/pointwise_conv/relu   (None, 24, 16, 128)      0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer4/depthwise_conv (Dept  (None, 24, 16, 128)      1152      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer4/depthwise_conv/bn (B  (None, 24, 16, 128)      384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer4/depthwise_conv/relu   (None, 24, 16, 128)      0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer4/pointwise_conv (Conv  (None, 24, 16, 128)      16384     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer4/pointwise_conv/bn (B  (None, 24, 16, 128)      384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer4/pointwise_conv/relu   (None, 24, 16, 128)      0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer5/depthwise_conv (Dept  (None, 12, 8, 128)       1152      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer5/depthwise_conv/bn (B  (None, 12, 8, 128)       384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer5/depthwise_conv/relu   (None, 12, 8, 128)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer5/pointwise_conv (Conv  (None, 12, 8, 256)       32768     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer5/pointwise_conv/bn (B  (None, 12, 8, 256)       768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer5/pointwise_conv/relu   (None, 12, 8, 256)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer6/depthwise_conv (Dept  (None, 12, 8, 256)       2304      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer6/depthwise_conv/bn (B  (None, 12, 8, 256)       768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer6/depthwise_conv/relu   (None, 12, 8, 256)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer6/pointwise_conv (Conv  (None, 12, 8, 256)       65536     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer6/pointwise_conv/bn (B  (None, 12, 8, 256)       768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer6/pointwise_conv/relu   (None, 12, 8, 256)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer7/depthwise_conv (Dept  (None, 6, 4, 256)        2304      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer7/depthwise_conv/bn (B  (None, 6, 4, 256)        768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer7/depthwise_conv/relu   (None, 6, 4, 256)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer7/pointwise_conv (Conv  (None, 6, 4, 512)        131072    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer7/pointwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer7/pointwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer8/depthwise_conv (Dept  (None, 6, 4, 512)        4608      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer8/depthwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer8/depthwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer8/pointwise_conv (Conv  (None, 6, 4, 512)        262144    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer8/pointwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer8/pointwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer9/depthwise_conv (Dept  (None, 6, 4, 512)        4608      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer9/depthwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer9/depthwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer9/pointwise_conv (Conv  (None, 6, 4, 512)        262144    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer9/pointwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer9/pointwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer10/depthwise_conv (Dep  (None, 6, 4, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer10/depthwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer10/depthwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer10/pointwise_conv (Con  (None, 6, 4, 512)        262144    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer10/pointwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer10/pointwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer11/depthwise_conv (Dep  (None, 6, 4, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer11/depthwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer11/depthwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer11/pointwise_conv (Con  (None, 6, 4, 512)        262144    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer11/pointwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer11/pointwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer12/depthwise_conv (Dep  (None, 6, 4, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer12/depthwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer12/depthwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer12/pointwise_conv (Con  (None, 6, 4, 512)        262144    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer12/pointwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer12/pointwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer13/depthwise_conv (Dep  (None, 3, 2, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer13/depthwise_conv/bn (  (None, 3, 2, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer13/depthwise_conv/relu  (None, 3, 2, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer13/pointwise_conv (Con  (None, 3, 2, 1024)       524288    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer13/pointwise_conv/bn (  (None, 3, 2, 1024)       3072      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer13/pointwise_conv/relu  (None, 3, 2, 1024)       0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer14/depthwise_conv (Dep  (None, 3, 2, 1024)       9216      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer14/depthwise_conv/bn (  (None, 3, 2, 1024)       3072      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer14/depthwise_conv/relu  (None, 3, 2, 1024)       0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer14/pointwise_conv (Con  (None, 3, 2, 1024)       1048576   \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer14/pointwise_conv/bn (  (None, 3, 2, 1024)       3072      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer14/pointwise_conv/relu  (None, 3, 2, 1024)       0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,224,519\n",
      "Trainable params: 3,202,631\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# NAME='./yamnet.h5'\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(NAME, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=10,\n",
    "                                            restore_best_weights=True,\n",
    "                                            verbose=1)\n",
    "\n",
    "# tensorboard=tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir='D:/bat_n/logs')\n",
    "\n",
    "yamnet.compile(optimizer='adam', \n",
    "               loss=\"categorical_crossentropy\", \n",
    "               metrics=[\n",
    "                        'accuracy',\n",
    "                        tf.keras.metrics.Recall(),\n",
    "                        tf.keras.metrics.Precision()\n",
    "                ]\n",
    ")\n",
    "\n",
    "yamnet.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    yamnet,\n",
    "    to_file='yamnet.png',\n",
    "    show_shapes=True,\n",
    "    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    "    layer_range=True,\n",
    "    show_layer_activations=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"reshape\" \"                 f\"(type Reshape).\n    \n    Cannot reshape a tensor with 18432 elements to shape [288,96,64,1] (1769472 elements) for '{{node yamnet_frames/reshape/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](IteratorGetNext, yamnet_frames/reshape/Reshape/shape)' with input shapes: [288,64], [4] and with input tensors computed as partial shapes: input[1] = [288,96,64,1].\n    \n    Call arguments received by layer \"reshape\" \"                 f\"(type Reshape):\n      • inputs=tf.Tensor(shape=(288, 64), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samin\\Documents\\Projects\\Emotion Detection\\notebook\\yamnet\\TL_yamnet.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m yamnet\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_ds,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m val_ds,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m# checkpoint,\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m# tensorboard,\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         callback\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samin/Documents/Projects/Emotion%20Detection/notebook/yamnet/TL_yamnet.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file10_amvha.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\samin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"reshape\" \"                 f\"(type Reshape).\n    \n    Cannot reshape a tensor with 18432 elements to shape [288,96,64,1] (1769472 elements) for '{{node yamnet_frames/reshape/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](IteratorGetNext, yamnet_frames/reshape/Reshape/shape)' with input shapes: [288,64], [4] and with input tensors computed as partial shapes: input[1] = [288,96,64,1].\n    \n    Call arguments received by layer \"reshape\" \"                 f\"(type Reshape):\n      • inputs=tf.Tensor(shape=(288, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yamnet.fit(\n",
    "    train_ds,\n",
    "    epochs=100, \n",
    "    validation_data= val_ds,\n",
    "    callbacks=[\n",
    "        # checkpoint,\n",
    "        # tensorboard,\n",
    "        callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "test_res = yamnet.evaluate(test_ds)\n",
    "\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dir_=\"D:/bat_n/df_test_b.csv\"\n",
    "#dir_=\"D:/bat_n/df_test_n.csv\"\n",
    "#dir_=\"D:/bat_n/df_test_uk.csv\"\n",
    "import os\n",
    "dir_=\"D:/bat_n/norfolk_test_files.csv\"\n",
    "df_test_b=pd.read_csv(dir_)\n",
    "base_data_path='D:/bat_n/wav/'\n",
    "full_path = df_test_b['filename'].apply(lambda row: os.path.join(base_data_path, row))\n",
    "df_test_b= df_test_b.assign(filename=full_path)\n",
    "\n",
    "full_path = df_test_b['filename'].apply(lambda row: ( row+ '.wav'))\n",
    "\n",
    "df_test_b= df_test_b.assign(filename=full_path)\n",
    "\n",
    "filenames=df_test_b['filename']\n",
    "targets=df_test_b['target']\n",
    "df_test_b['fold']=1\n",
    "folds=df_test_b['fold']\n",
    "\n",
    "\n",
    "#the directory contained the .wav files\n",
    "\n",
    "test_b = tf.data.Dataset.from_tensor_slices((filenames, targets,folds))\n",
    "test_b= test_b.map(load_wav_for_map)\n",
    "test_b = test_b.map(yamnet_frames_model_transfer1).unbatch()\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "test_b = test_b.map(remove_fold_column)\n",
    "test_b = test_b.cache().batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "evaluate= yamnet.evaluate(test_b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dir_=\"D:/bat_n/df_test_uk.csv\"\n",
    "dir_=\"D:/bat_n/uk_test_files1.csv\"\n",
    "df_test_b=pd.read_csv(dir_)\n",
    "\n",
    "\n",
    "filenames=df_test_b['filename']\n",
    "targets=df_test_b['target']\n",
    "df_test_b['fold']=1\n",
    "folds=df_test_b['fold']\n",
    "\n",
    "\n",
    "#the directory contained the .wav files\n",
    "\n",
    "test_b = tf.data.Dataset.from_tensor_slices((filenames, targets,folds))\n",
    "test_b= test_b.map(load_wav_for_map)\n",
    "test_b = test_b.map(yamnet_frames_model_transfer1).unbatch()\n",
    "cached_ds = main_ds.cache()\n",
    "test_b_train = cached_ds.filter(lambda embedding, label, fold: fold <2)\n",
    "test_b_val = cached_ds.filter(lambda embedding, label, fold: fold ==3)\n",
    "test_b_test = cached_ds.filter(lambda embedding, label, fold: fold == 4)\n",
    "\n",
    "# remove the folds column now that it's not needed anymore\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "\n",
    "test_b_train= test_b_train.map(remove_fold_column)\n",
    "\n",
    "test_b_val= test_b_val.map(remove_fold_column)\n",
    "\n",
    "test_b_test= test_b_test.map(remove_fold_column)\n",
    "\n",
    "\n",
    "#X_train = list(map(lambda x: x[0], train_ds))\n",
    "#y_train = list(map(lambda x: x[1], train_ds))\n",
    "\n",
    "#creat a batch of size 32 of frames with size (96,64)\n",
    "#we have to suffle the train set to avoid the frames from the same audio on one batch\n",
    "train_ds = test_b_train.cache().shuffle(1000).batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "val_ds = test_b_val.cache().batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_b_test.cache().batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "#test n\n",
    "\n",
    "'''\n",
    "dir_=\"D:/bat_n/df_test_n.csv\"\n",
    "dir_=\"D:/bat_n/df_test_uk.csv\"\n",
    "df_test_b=pd.read_csv(dir_)\n",
    "\n",
    "filenames=df_test_b['filename']\n",
    "targets=df_test_b['target']\n",
    "folds=df_test_b['fold']\n",
    "l=[]\n",
    "for j in range(1,5):\n",
    "    print((j-1),'--',j*175)\n",
    "    for i in range(0,175):\n",
    "        \n",
    "        l.append(j)\n",
    "        \n",
    "        \n",
    "        \n",
    "folds=l[:len(df_test_b)]        \n",
    "        \n",
    "    \n",
    "\n",
    "test_b = tf.data.Dataset.from_tensor_slices((filenames, targets,folds))\n",
    "test_b= test_b.map(load_wav_for_map)\n",
    "\n",
    "test_b = test_b.map(yamnet_frames_model_transfer1)#.unbatch()\n",
    "\n",
    "\n",
    "cached_ds = test_b.cache()\n",
    "test_b_train = cached_ds.filter(lambda embedding, label, fold: fold <2)\n",
    "test_b_val = cached_ds.filter(lambda embedding, label, fold: fold ==3)\n",
    "test_b_test = cached_ds.filter(lambda embedding, label, fold: fold <= 2)\n",
    "\n",
    "# remove the folds column now that it's not needed anymore\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "\n",
    "test_b_train= test_b_train.map(remove_fold_column)\n",
    "\n",
    "test_b_val= test_b_val.map(remove_fold_column)\n",
    "\n",
    "test_b_test= test_b_test.map(remove_fold_column)\n",
    "\n",
    "\n",
    "\n",
    "#creat a batch of size 32 of frames with size (96,64)\n",
    "#we have to suffle the train set to avoid the frames from the same audio on one batch\n",
    "train_ds = test_b_train.cache().shuffle(1000).batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "val_ds = test_b_val.cache().batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_b_test.cache().batch(32).prefetch( tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "yamnet=yamnet_model.yamnet_frames_model_transfer(params)\n",
    "\n",
    "preloaded_layers = yamnet.layers.copy()\n",
    "preloaded_weights = []\n",
    "for pre in preloaded_layers:\n",
    "        preloaded_weights.append(pre.get_weights())    \n",
    "\n",
    "\n",
    "#load the weights from pretrain model except for the last layer and\n",
    "#check which layer used the pretrain weights\n",
    "# store weights before loading pre-trained weights\n",
    "chkp==True\n",
    "if chkp==True:\n",
    "# load pre-trained weights(fine tuning the model)\n",
    "#load the weights from pretrain model except for the last layer\n",
    "    yamnet.load_weights('D:/bat_n/yamnet_2.h5',by_name=True)\n",
    "    for layer, pre in zip(yamnet.layers, preloaded_weights):\n",
    "        weights = layer.get_weights()\n",
    "        if weights:\n",
    "            if np.array_equal(weights, pre):\n",
    "                print('not loaded', layer.name)\n",
    "            else:\n",
    "                print('loaded', layer.name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "yamnet.compile(optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy', \n",
    "               metrics=['accuracy'])\n",
    "yamnet.fit(train_ds,epochs=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss= yamnet.evaluate(test_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "import numpy as np\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "X=list(map(lambda x: x[0], test_b))\n",
    "X=np.array(X)\n",
    "#y_train = list(map(lambda x: x[1], train_ds))\n",
    "augment = Compose([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "        ])\n",
    "augmented_samples = augment(samples=X, sample_rate=16000)\n",
    "    \n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d160966f923a3a33b7e4678143d4ddbf9984fa94549c4439610f55de51f406fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
