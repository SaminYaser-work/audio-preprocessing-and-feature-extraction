{"cells":[{"cell_type":"markdown","metadata":{"id":"5fbCls1d2yBs"},"source":["# Emotion Recognition Using HuBERT"]},{"cell_type":"markdown","metadata":{"id":"sp37lZOV2042"},"source":["**HuBERT** leverages the masked prediction loss over sequences, e.g., \n","Googleâ€™s Bidirectional Encoder Representations from Transformers, or BERT, method, to represent the sequential structure of speech. HuBERT uses an offline clustering step to generate noisy labels for Masked Language Model pretraining. Concretely, HuBERT consumes masked continuous speech features to predict predetermined cluster assignments. The predictive loss is applied over only the masked regions, forcing the model to learn good high-level representations of unmasked inputs in order to infer the targets of masked ones correctly.\n","\n","The official [paper](https://arxiv.org/pdf/2106.07447.pdf)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-04T13:41:25.970132Z","iopub.status.busy":"2022-12-04T13:41:25.967726Z","iopub.status.idle":"2022-12-04T13:41:25.978896Z","shell.execute_reply":"2022-12-04T13:41:25.977983Z","shell.execute_reply.started":"2022-12-04T13:41:25.970091Z"},"id":"pFSqZ0jwCMSv","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from pathlib import Path\n","from tqdm import tqdm\n","import re\n","\n","# import torchaudio\n","from sklearn.model_selection import train_test_split\n","\n","import os\n","import sys\n","\n","from datasets import load_from_disk\n","import shutil\n","from pathlib import Path\n","import wandb\n","import librosa\n","from datasets import load_dataset, load_metric\n","from sklearn.metrics import classification_report\n","from transformers import AutoConfig, Wav2Vec2Processor, Wav2Vec2FeatureExtractor\n","from dataclasses import dataclass\n","from typing import Dict, List, Optional, Union\n","import torch\n","\n","import transformers\n","from transformers import Wav2Vec2FeatureExtractor\n","\n","from typing import Optional, Tuple\n","import torch\n","from transformers.file_utils import ModelOutput\n","import numpy as np\n","from transformers import EvalPrediction\n","from transformers import TrainingArguments\n","from typing import Any, Dict, Union\n","from transformers import AutoConfig, Wav2Vec2Processor, Wav2Vec2FeatureExtractor\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n","from transformers.models.hubert.modeling_hubert import (\n","    HubertPreTrainedModel,\n","    HubertModel\n",")\n","\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-04T13:41:25.992456Z","iopub.status.busy":"2022-12-04T13:41:25.991197Z","iopub.status.idle":"2022-12-04T13:41:26.000505Z","shell.execute_reply":"2022-12-04T13:41:25.999181Z","shell.execute_reply.started":"2022-12-04T13:41:25.992420Z"},"id":"rsOrQPBOEVOy","trusted":true},"outputs":[],"source":["dses = ['savee', 'ravdess', 'tess', 'crema', 'bser', 'subesco']\n","augs = [False, True]\n","variants = ['base', 'large']\n","\n","comb = list(itertools.product(dses, augs, variants))\n","\n","comb.append(('all_bn', False, 'base'))\n","comb.append(('all_en', False, 'base'))\n","comb.append(('all', False, 'base'))\n","\n","print(comb)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def start_training(combs):\n","\n","    for comb in combs:\n","\n","        ds = comb[0]\n","        aug = comb[1]\n","        variant = comb[2]\n","\n","        input_column = \"path\"\n","        output_column = \"emotion\"\n","\n","\n","        if variant == 'base':\n","            model_name_or_path = \"facebook/hubert-base-ls960\"\n","        else:\n","            model_name_or_path = 'facebook/hubert-large-ls960-ft'\n","\n","        pooling_mode = \"mean\"\n","\n","        if aug:\n","            train_dir = f'../input/hf-hubert-ser/hf_datasets/{ds}/{variant}/train'\n","        else:\n","            train_dir = f'../input/hf-hubert-ser/hf_datasets/{ds}/{variant}/train_aug'\n","\n","        val_dir = f'../input/hf-hubert-ser/hf_datasets/{ds}/{variant}/val'\n","        test_dir = f'../input/hf-hubert-ser/hf_datasets/{ds}/{variant}/test'\n","\n","        print(train_dir)\n","\n","        # # Uncomment this part if you want to setup your wandb project\n","        %env WANDB_WATCH=all\n","        %env WANDB_LOG_MODEL=1\n","        # %env WANDB_PROJECT=YOUR_PROJECT_NAME\n","        !wandb login f3417b4f564d8a58bbdcd6731ab041c2f58210c6 --relogin\n","        wandb_name = f'{ds}_{variant}_{aug}'\n","        wandb.init(\n","            project=\"hubert-ser_v2\", \n","            entity=\"f00d\",\n","            name=wandb_name,\n","        )\n","\n","        if ds == 'crema' or ds == 'crema_no_aug':\n","            label_list = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad']\n","        elif ds == 'bser' or ds == 'bser_no_aug':\n","            label_list = ['angry', 'happy', 'neutral', 'sad', 'surprise']\n","        else:\n","            label_list = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","            \n","            \n","        num_labels = len(label_list)\n","        num_labels\n","        # config\n","        config = AutoConfig.from_pretrained(\n","            model_name_or_path,\n","            num_labels=num_labels,\n","            label2id={label: i for i, label in enumerate(label_list)},\n","            id2label={i: label for i, label in enumerate(label_list)},\n","            finetuning_task=\"wav2vec2_clf\",\n","        )\n","        setattr(config, 'pooling_mode', pooling_mode)\n","        feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path,)\n","        target_sampling_rate = feature_extractor.sampling_rate\n","        print(f\"The target sampling rate: {target_sampling_rate}\")\n","        # Preprocess Data\n","        def speech_file_to_array_fn(path):\n","        #     speech_array, sampling_rate = torchaudio.load(path)\n","        #     resampler = torchaudio.transforms.Resample(sampling_rate, target_sampling_rate)\n","        #     speech = resampler(speech_array).squeeze().numpy()\n","            \n","            speech_array, sampling_rate = librosa.load(path)\n","            resampler = librosa.resample(speech_array, orig_sr=sampling_rate, target_sr=target_sampling_rate, res_type=\"kaiser_best\")\n","            return resampler\n","\n","        def label_to_id(label, label_list):\n","            if len(label_list) > 0:\n","                return label_list.index(label) if label in label_list else -1\n","            return label\n","\n","        def preprocess_function(examples):\n","            speech_list = [speech_file_to_array_fn(path) for path in examples[input_column]]\n","            target_list = [label_to_id(label, label_list) for label in examples[output_column]]\n","\n","            result = feature_extractor(speech_list, sampling_rate=target_sampling_rate)\n","            result[\"labels\"] = list(target_list)\n","\n","            return result\n","\n","        train_dataset = load_from_disk(train_dir)\n","        eval_dataset = load_from_disk(val_dir)\n","\n","        dirpath = Path('./test')\n","        if dirpath.exists() and dirpath.is_dir():\n","            shutil.rmtree(dirpath)\n","            \n","        shutil.copytree(test_dir, './test')\n","\n","        test_dataset = load_from_disk('./test')\n","\n","\n","\n","        @dataclass\n","        class SpeechClassifierOutput(ModelOutput):\n","            loss: Optional[torch.FloatTensor] = None\n","            logits: torch.FloatTensor = None\n","            hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n","            attentions: Optional[Tuple[torch.FloatTensor]] = None\n","\n","\n","\n","        class HubertClassificationHead(nn.Module):\n","            \"\"\"Head for hubert classification task.\"\"\"\n","\n","            def __init__(self, config):\n","                super().__init__()\n","                self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n","                self.dropout = nn.Dropout(config.final_dropout)\n","                self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n","\n","            def forward(self, features, **kwargs):\n","                x = features\n","                x = self.dropout(x)\n","                x = self.dense(x)\n","                x = torch.tanh(x)\n","                x = self.dropout(x)\n","                x = self.out_proj(x)\n","                return x\n","\n","\n","        class HubertForSpeechClassification(HubertPreTrainedModel):\n","            def __init__(self, config):\n","                super().__init__(config)\n","                self.num_labels = config.num_labels\n","                self.pooling_mode = config.pooling_mode\n","                self.config = config\n","\n","                self.hubert = HubertModel(config)\n","                self.classifier = HubertClassificationHead(config)\n","\n","                self.init_weights()\n","\n","            def freeze_feature_extractor(self):\n","                self.hubert.feature_extractor._freeze_parameters()\n","\n","            def merged_strategy(\n","                    self,\n","                    hidden_states,\n","                    mode=\"mean\"\n","            ):\n","                if mode == \"mean\":\n","                    outputs = torch.mean(hidden_states, dim=1)\n","                elif mode == \"sum\":\n","                    outputs = torch.sum(hidden_states, dim=1)\n","                elif mode == \"max\":\n","                    outputs = torch.max(hidden_states, dim=1)[0]\n","                else:\n","                    raise Exception(\n","                        \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n","\n","                return outputs\n","\n","            def forward(\n","                    self,\n","                    input_values,\n","                    attention_mask=None,\n","                    output_attentions=None,\n","                    output_hidden_states=None,\n","                    return_dict=None,\n","                    labels=None,\n","            ):\n","                return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","                outputs = self.hubert(\n","                    input_values,\n","                    attention_mask=attention_mask,\n","                    output_attentions=output_attentions,\n","                    output_hidden_states=output_hidden_states,\n","                    return_dict=return_dict,\n","                )\n","                hidden_states = outputs[0]\n","                hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n","                logits = self.classifier(hidden_states)\n","\n","                loss = None\n","                if labels is not None:\n","                    if self.config.problem_type is None:\n","                        if self.num_labels == 1:\n","                            self.config.problem_type = \"regression\"\n","                        elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n","                            self.config.problem_type = \"single_label_classification\"\n","                        else:\n","                            self.config.problem_type = \"multi_label_classification\"\n","\n","                    if self.config.problem_type == \"regression\":\n","                        loss_fct = MSELoss()\n","                        loss = loss_fct(logits.view(-1, self.num_labels), labels)\n","                    elif self.config.problem_type == \"single_label_classification\":\n","                        loss_fct = CrossEntropyLoss()\n","                        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","                    elif self.config.problem_type == \"multi_label_classification\":\n","                        loss_fct = BCEWithLogitsLoss()\n","                        loss = loss_fct(logits, labels)\n","\n","                if not return_dict:\n","                    output = (logits,) + outputs[2:]\n","                    return ((loss,) + output) if loss is not None else output\n","\n","                return SpeechClassifierOutput(\n","                    loss=loss,\n","                    logits=logits,\n","                    hidden_states=outputs.hidden_states,\n","                    attentions=outputs.attentions,\n","                )\n","\n","\n","\n","        @dataclass\n","        class DataCollatorCTCWithPadding:\n","            \"\"\"\n","            Data collator that will dynamically pad the inputs received.\n","            Args:\n","                feature_extractor (:class:`~transformers.Wav2Vec2FeatureExtractor`)\n","                    The feature_extractor used for proccessing the data.\n","                padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n","                    Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n","                    among:\n","                    * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n","                    sequence if provided).\n","                    * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n","                    maximum acceptable input length for the model if that argument is not provided.\n","                    * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n","                    different lengths).\n","                max_length (:obj:`int`, `optional`):\n","                    Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n","                max_length_labels (:obj:`int`, `optional`):\n","                    Maximum length of the ``labels`` returned list and optionally padding length (see above).\n","                pad_to_multiple_of (:obj:`int`, `optional`):\n","                    If set will pad the sequence to a multiple of the provided value.\n","                    This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n","                    7.5 (Volta).\n","            \"\"\"\n","\n","            feature_extractor: Wav2Vec2FeatureExtractor\n","            padding: Union[bool, str] = True\n","            max_length: Optional[int] = None\n","            max_length_labels: Optional[int] = None\n","            pad_to_multiple_of: Optional[int] = None\n","            pad_to_multiple_of_labels: Optional[int] = None\n","\n","            def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","                input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n","                label_features = [feature[\"labels\"] for feature in features]\n","\n","                d_type = torch.long if isinstance(label_features[0], int) else torch.float\n","\n","                batch = self.feature_extractor.pad(\n","                    input_features,\n","                    padding=self.padding,\n","                    max_length=self.max_length,\n","                    pad_to_multiple_of=self.pad_to_multiple_of,\n","                    return_tensors=\"pt\",\n","                )\n","\n","                batch[\"labels\"] = torch.tensor(label_features, dtype=d_type)\n","\n","                return batch\n","        data_collator = DataCollatorCTCWithPadding(feature_extractor=feature_extractor, padding=True)\n","\n","        is_regression = False\n","\n","\n","        def compute_metrics(p: EvalPrediction):\n","            preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","            preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)\n","\n","            if is_regression:\n","                return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}\n","            else:\n","                return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n","\n","        drive_dir = \"./\"\n","        !ls {drive_dir}\n","        output_dir = os.path.join(drive_dir, \"ckpts\", \"hubert-base-english-ser\")\n","        !ls {output_dir}\n","        import os\n","        import shutil\n","\n","        last_checkpoint = None\n","        checkpoints = []\n","        if os.path.exists(output_dir):\n","            for subdir in os.scandir(output_dir):\n","                if subdir.is_dir():\n","                    checkpoints.append(subdir.path)\n","                    \n","                    \n","        if len(checkpoints) > 0:\n","            checkpoints = list(sorted(checkpoints, key=lambda ckpt: ckpt.split('/')[-1].split('-')[-1], reverse=True))\n","            model_name_or_path = os.path.join(\"./\", checkpoints[0].split(\"/\")[-1])\n","            last_checkpoint = model_name_or_path\n","            shutil.copytree(checkpoints[0], model_name_or_path)\n","        print(f\"model_name_or_path: {model_name_or_path}\")\n","        print(f\"last_checkpoint: {last_checkpoint}\")\n","        model = HubertForSpeechClassification.from_pretrained(\n","            model_name_or_path,\n","            config=config,\n","        )\n","\n","\n","        training_args = TrainingArguments(\n","            output_dir=output_dir,\n","            per_device_train_batch_size=4,\n","            per_device_eval_batch_size=4,\n","            gradient_accumulation_steps=2,\n","            evaluation_strategy=\"steps\",\n","            save_strategy=\"steps\",\n","            num_train_epochs=5.0,\n","            fp16=True,\n","            save_steps=500,\n","            eval_steps=500,\n","            logging_steps=500,\n","            learning_rate=1e-4,\n","            save_total_limit=1,\n","            do_train=True,\n","            do_eval=True,\n","            do_predict=True,\n","            report_to=\"wandb\",\n","            load_best_model_at_end=True,\n","            metric_for_best_model='accuracy'\n","        #     push_to_hub = True\n","        )\n","\n","        import torch\n","        from packaging import version\n","        from torch import nn\n","\n","        from transformers import (\n","            Trainer,\n","            is_apex_available,\n","        )\n","\n","        if is_apex_available():\n","            from apex import amp\n","\n","        if version.parse(torch.__version__) >= version.parse(\"1.6\"):\n","            _is_native_amp_available = True\n","            from torch.cuda.amp import autocast\n","\n","\n","        class CTCTrainer(Trainer):\n","            def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n","                \"\"\"\n","                Perform a training step on a batch of inputs.\n","\n","                Subclass and override to inject custom behavior.\n","\n","                Args:\n","                    model (:obj:`nn.Module`):\n","                        The model to train.\n","                    inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n","                        The inputs and targets of the model.\n","\n","                        The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n","                        argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n","\n","                Return:\n","                    :obj:`torch.Tensor`: The tensor with training loss on this batch.\n","                \"\"\"\n","\n","        #         model.train()\n","        #         inputs = self._prepare_inputs(inputs)\n","\n","        #         if self.use_amp:\n","        #             with autocast():\n","        #                 loss = self.compute_loss(model, inputs)\n","        #         else:\n","        #             loss = self.compute_loss(model, inputs)\n","\n","        #         if self.args.gradient_accumulation_steps > 1:\n","        #             loss = loss / self.args.gradient_accumulation_steps\n","\n","        #         if self.use_amp:\n","        #             self.scaler.scale(loss).backward()\n","        #         elif self.use_apex:\n","        #             with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n","        #                 scaled_loss.backward()\n","        #         elif self.deepspeed:\n","        #             self.deepspeed.backward(loss)\n","        #         else:\n","        #             loss.backward()\n","\n","        #         return loss.detach()\n","            \n","                model.train()\n","                inputs = self._prepare_inputs(inputs)\n","\n","                with autocast():\n","                    loss = self.compute_loss(model, inputs)\n","\n","                if self.args.gradient_accumulation_steps > 1:\n","                    loss = loss / self.args.gradient_accumulation_steps\n","\n","\n","                self.scaler.scale(loss).backward()\n","\n","\n","                return loss.detach()\n","\n","        trainer = CTCTrainer(\n","            model=model,\n","            data_collator=data_collator,\n","            args=training_args,\n","            compute_metrics=compute_metrics,\n","            train_dataset=train_dataset,\n","            eval_dataset=eval_dataset,\n","            tokenizer=feature_extractor,\n","        )\n","        if training_args.do_train:\n","            print(f\"last_checkpoint: {last_checkpoint}\")\n","            train_result = trainer.train(resume_from_checkpoint=last_checkpoint)\n","            trainer.save_model()\n","            feature_extractor.save_pretrained(training_args.output_dir)\n","            metrics = train_result.metrics\n","            metrics[\"train_samples\"] = len(train_dataset)\n","\n","            trainer.log_metrics(\"train\", metrics)\n","            trainer.save_metrics(\"train\", metrics)\n","            trainer.save_state()\n","        # test_dataset = load_dataset(\"csv\", data_files={\"test\": \"./test.csv\"}, delimiter=\"\\t\")[\"test\"]\n","        # test_dataset\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        print(f\"Device: {device}\")\n","        # model_name_or_path = \"m3hrdadfi/hubert-base-greek-speech-emotion-recognition\"\n","        # config = AutoConfig.from_pretrained(model_name_or_path)\n","        # feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path)\n","        # model = HubertForSpeechClassification.from_pretrained(model_name_or_path).to(device)\n","        def speech_file_to_array_fn(batch):\n","        #     speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n","        #     speech_array = speech_array.squeeze().numpy()\n","            speech_array, sampling_rate = librosa.load(batch[\"path\"])\n","            speech_array = librosa.resample(speech_array, sampling_rate, feature_extractor.sampling_rate)\n","\n","            batch[\"speech\"] = speech_array\n","            return batch\n","\n","\n","        def predict(batch):\n","            features = feature_extractor(batch[\"speech\"], sampling_rate=feature_extractor.sampling_rate, return_tensors=\"pt\", padding=True)\n","\n","            input_values = features.input_values.to(device)\n","\n","            with torch.no_grad():\n","                logits = model(input_values).logits \n","\n","            pred_ids = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n","            batch[\"predicted\"] = pred_ids\n","            return batch\n","        result = test_dataset.map(predict, batched=True, batch_size=2)\n","        label_names = [config.id2label[i] for i in range(config.num_labels)]\n","        label_names\n","        y_true = [config.label2id[name] for name in result[\"emotion\"]]\n","        y_pred = result[\"predicted\"]\n","\n","        # print(y_true[:5])\n","        # print(y_pred[:5])\n","        print(classification_report(y_true, y_pred, target_names=label_names, digits=6))\n","\n","        print('f1_weighted:', f1_score(y_true, y_pred, average='weighted'))\n","        print('Pre_weighted:', precision_score(y_true, y_pred, average='weighted'))\n","        print('Re_weighted:', recall_score(y_true, y_pred, average='weighted'))\n","        print('Acc:', accuracy_score(y_true, y_pred))\n","\n","\n","        cm = confusion_matrix(y_true, y_pred)\n","        print('cm:', cm)\n","\n","        wandb.log(\n","            {\n","                \"f1_weighted\": f1_score(y_true, y_pred, average='weighted'),\n","                \"Pre_weighted\": precision_score(y_true, y_pred, average='weighted'),\n","                \"Re_weighted\": recall_score(y_true, y_pred, average='weighted'),\n","                \"Acc\": accuracy_score(y_true, y_pred),\n","                \"cm\" : cm\n","            }\n","        )\n","\n","        cm = cm / cm.astype(float).sum(axis=1)\n","        # print('cm_norm:', cm)\n","\n","        ax= plt.subplot()\n","        sns.heatmap(cm, annot=True, fmt='.2g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","\n","        # labels, title and ticks\n","        ax.set_xlabel('Predicted labels')\n","        ax.set_ylabel('True labels') \n","        ax.set_title('Confusion Matrix') \n","        ax.xaxis.set_ticklabels(label_names)\n","        ax.yaxis.set_ticklabels(label_names)\n","\n","        wandb.alert(\n","            title=\"Done\", \n","            text=f\"done with {wandb_name}\"\n","        )\n","\n","        # trainer.save_model(\"./hubert\")\n","        # shutil.make_archive('hubert_all_7_aug_large', 'zip', './hubert')\n","\n","        wandb.finish()\n","        !rm -rf /kaggle/working/*"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":4}
