{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 07:25:18.634140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-19 07:25:33.138203: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:25:33.138235: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-19 07:25:34.376608: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-19 07:25:55.820774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:25:55.820917: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:25:55.820925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES5 = ['angry', 'happy', 'neutral', 'sad', 'surprise']\n",
    "CLASSES6 = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad']\n",
    "CLASSES7 = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 07:27:31.190506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-19 07:27:31.190796: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.190891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.190947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.191038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.191089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.191155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.191222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.191271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-19 07:27:31.191279: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-19 07:27:31.191850: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'vggish_emb'\n",
    "# Load the model.\n",
    "# model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "model = hub.load('https://tfhub.dev/google/vggish/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>emotion</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Datasets/custom_db/tess/train/angry_1068.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>train</td>\n",
       "      <td>tess</td>\n",
       "      <td>none</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Datasets/custom_db/tess/train/surprise_1286...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>train</td>\n",
       "      <td>tess</td>\n",
       "      <td>none</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Datasets/custom_db/tess/train/fear_248.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>train</td>\n",
       "      <td>tess</td>\n",
       "      <td>none</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Datasets/custom_db/tess/train/happy_2790.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>train</td>\n",
       "      <td>tess</td>\n",
       "      <td>none</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Datasets/custom_db/tess/train/surprise_139.wav</td>\n",
       "      <td>surprise</td>\n",
       "      <td>train</td>\n",
       "      <td>tess</td>\n",
       "      <td>none</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92777</th>\n",
       "      <td>../Datasets/custom_db/bser/augment/happy_1017_...</td>\n",
       "      <td>happy</td>\n",
       "      <td>augment</td>\n",
       "      <td>bser</td>\n",
       "      <td>freqmask</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92778</th>\n",
       "      <td>../Datasets/custom_db/bser/augment/happy_660_p...</td>\n",
       "      <td>happy</td>\n",
       "      <td>augment</td>\n",
       "      <td>bser</td>\n",
       "      <td>pitchshift</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92779</th>\n",
       "      <td>../Datasets/custom_db/bser/augment/neutral_479...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>augment</td>\n",
       "      <td>bser</td>\n",
       "      <td>freqmask</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92780</th>\n",
       "      <td>../Datasets/custom_db/bser/augment/happy_841_t...</td>\n",
       "      <td>happy</td>\n",
       "      <td>augment</td>\n",
       "      <td>bser</td>\n",
       "      <td>timemask</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92781</th>\n",
       "      <td>../Datasets/custom_db/bser/augment/happy_309_f...</td>\n",
       "      <td>happy</td>\n",
       "      <td>augment</td>\n",
       "      <td>bser</td>\n",
       "      <td>freqmask</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92782 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file   emotion    split  \\\n",
       "0        ../Datasets/custom_db/tess/train/angry_1068.wav     angry    train   \n",
       "1      ../Datasets/custom_db/tess/train/surprise_1286...  surprise    train   \n",
       "2          ../Datasets/custom_db/tess/train/fear_248.wav      fear    train   \n",
       "3        ../Datasets/custom_db/tess/train/happy_2790.wav     happy    train   \n",
       "4      ../Datasets/custom_db/tess/train/surprise_139.wav  surprise    train   \n",
       "...                                                  ...       ...      ...   \n",
       "92777  ../Datasets/custom_db/bser/augment/happy_1017_...     happy  augment   \n",
       "92778  ../Datasets/custom_db/bser/augment/happy_660_p...     happy  augment   \n",
       "92779  ../Datasets/custom_db/bser/augment/neutral_479...   neutral  augment   \n",
       "92780  ../Datasets/custom_db/bser/augment/happy_841_t...     happy  augment   \n",
       "92781  ../Datasets/custom_db/bser/augment/happy_309_f...     happy  augment   \n",
       "\n",
       "      dataset augmentation language  \n",
       "0        tess         none       en  \n",
       "1        tess         none       en  \n",
       "2        tess         none       en  \n",
       "3        tess         none       en  \n",
       "4        tess         none       en  \n",
       "...       ...          ...      ...  \n",
       "92777    bser     freqmask       bn  \n",
       "92778    bser   pitchshift       bn  \n",
       "92779    bser     freqmask       bn  \n",
       "92780    bser     timemask       bn  \n",
       "92781    bser     freqmask       bn  \n",
       "\n",
       "[92782 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Datasets/custom_db/df.csv')\n",
    "df['file'] = df['file'].apply(lambda x: '../Datasets/custom_db/' + x[2:])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(filename, label):\n",
    "    data, sr = librosa.load(filename, sr=None, mono=True, res_type='kaiser_best')\n",
    "\n",
    "    if sr != 16000:\n",
    "        raise ValueError('Sample rate is not 16kHz!')\n",
    "\n",
    "    embeddings = model(data)\n",
    "    # _, embeddings, _ = model(data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return embeddings, tf.repeat(label, num_embeddings)\n",
    "\n",
    "frame_length = 9288\n",
    "frame_step = frame_length // 2\n",
    "\n",
    "\n",
    "def get_embeddings_v2(filename, label):\n",
    "    data, sr = librosa.load(filename, sr=None, mono=True, res_type='kaiser_best')\n",
    "    data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "    clips = tf.signal.frame(\n",
    "        data, frame_length=frame_length, frame_step=frame_step)\n",
    "    batch_labels = tf.repeat(tf.expand_dims(label, 0), len(clips))\n",
    "    batch_labels = batch_labels.numpy()\n",
    "\n",
    "    print(len(clips[0]))\n",
    "\n",
    "    embs = []\n",
    "    for clip in clips:\n",
    "        # _, embeddings, _ = model(clip)\n",
    "        embeddings = model(clip)\n",
    "        print(embeddings)\n",
    "        embedding = np.mean(embeddings, axis=0)\n",
    "        embs.append(embedding)\n",
    "    embs = np.array(embs)\n",
    "\n",
    "    return embs, batch_labels\n",
    "\n",
    "def get_embeddings_v3(filename, label):\n",
    "    data, sr = librosa.load(filename, sr=None, mono=True, res_type='kaiser_best')\n",
    "\n",
    "    if len(data) < 16000:\n",
    "        # data = np.pad(data, (0, 16000 - len(data)), 'constant')\n",
    "        raise ValueError('Audio length is less than 1 second!')\n",
    "    if sr != 16000:\n",
    "        raise ValueError('Sample rate is not 16kHz!')\n",
    "\n",
    "\n",
    "    # embeddings = model(data)\n",
    "    _, embeddings, _ = model(data)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return embeddings, tf.repeat(label, num_embeddings).numpy()\n",
    "\n",
    "    # print(len(clips[0]))\n",
    "\n",
    "    # embs = []\n",
    "    # for clip in clips:\n",
    "    #     # _, embeddings, _ = model(clip)\n",
    "    #     embeddings = model(clip)\n",
    "    #     print(embeddings)\n",
    "    #     embedding = np.mean(embeddings, axis=0)\n",
    "    #     embs.append(embedding)\n",
    "    # embs = np.array(embs)\n",
    "\n",
    "    # return embs, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r, s = get_embeddings(df['file'][86223], df['emotion'][86223])\n",
    "# r, s = get_embeddings(df['file'][0], df['emotion'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.shape, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p, q = get_embeddings_v3(df['file'][86223], df['emotion'][86223])\n",
    "# # p, q = get_embeddings_v3(df['file'][0], df['emotion'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(df, filename, split):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    if df['emotion'].nunique() == 6:\n",
    "        classes = CLASSES6\n",
    "    elif df['emotion'].nunique() == 5:\n",
    "        classes = CLASSES5\n",
    "    else:\n",
    "        classes = CLASSES7\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        embs, label = get_embeddings_v3(row['file'], row['emotion'])\n",
    "        assert(len(embs) == len(label))\n",
    "        features.extend(embs)\n",
    "        labels.extend(label)\n",
    "\n",
    "        # for i in range(embs.shape[0]):\n",
    "        #     features.append(embs[i])\n",
    "        #     labels.append(classes.index(label[i]))\n",
    "    \n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    np.save(filename + split + '_X.npy', features)\n",
    "    np.save(filename + split + '_y.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6047/6047 [05:33<00:00, 18.16it/s]\n",
      "100%|██████████| 1008/1008 [00:39<00:00, 25.27it/s]\n",
      "100%|██████████| 144/144 [00:05<00:00, 24.14it/s]\n",
      "100%|██████████| 288/288 [00:12<00:00, 23.12it/s]\n"
     ]
    }
   ],
   "source": [
    "ravdess = df[df['dataset'] == 'ravdess']\n",
    "\n",
    "train_aug = ravdess[(ravdess['split'] == 'train') | (ravdess['split'] == 'augment')]\n",
    "train = ravdess[ravdess['split'] == 'train']\n",
    "val = ravdess[ravdess['split'] == 'val']\n",
    "test = ravdess[ravdess['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/ravdess/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/ravdess/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/ravdess/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/ravdess/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2014/2014 [01:57<00:00, 17.09it/s]\n",
      "100%|██████████| 336/336 [00:15<00:00, 21.45it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 19.59it/s]\n",
      "100%|██████████| 96/96 [00:04<00:00, 20.25it/s]\n"
     ]
    }
   ],
   "source": [
    "savee = df[df['dataset'] == 'savee']\n",
    "\n",
    "train_aug = savee[(savee['split'] == 'train') | (savee['split'] == 'augment')]\n",
    "train = savee[savee['split'] == 'train']\n",
    "val = savee[savee['split'] == 'val']\n",
    "test = savee[savee['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/savee/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/savee/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/savee/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/savee/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11753/11753 [10:23<00:00, 18.85it/s]\n",
      "100%|██████████| 1960/1960 [01:10<00:00, 27.91it/s]\n",
      "100%|██████████| 280/280 [00:10<00:00, 26.16it/s]\n",
      "100%|██████████| 560/560 [00:21<00:00, 26.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tess = df[df['dataset'] == 'tess']\n",
    "\n",
    "train_aug = tess[(tess['split'] == 'train') | (tess['split'] == 'augment')]\n",
    "train = tess[tess['split'] == 'train']\n",
    "val = tess[tess['split'] == 'val']\n",
    "test = tess[tess['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/tess/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/tess/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/tess/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/tess/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31237/31237 [28:28<00:00, 18.28it/s]\n",
      "100%|██████████| 5208/5208 [04:24<00:00, 19.65it/s]\n",
      "100%|██████████| 745/745 [00:33<00:00, 22.01it/s]\n",
      "100%|██████████| 1489/1489 [01:14<00:00, 19.92it/s]\n"
     ]
    }
   ],
   "source": [
    "crema = df[df['dataset'] == 'crema']\n",
    "\n",
    "train_aug = crema[(crema['split'] == 'train') | (crema['split'] == 'augment')]\n",
    "train = crema[crema['split'] == 'train']\n",
    "val = crema[crema['split'] == 'val']\n",
    "test = crema[crema['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/crema/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/crema/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/crema/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/crema/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29386/29386 [25:49<00:00, 18.96it/s]\n",
      "100%|██████████| 4900/4900 [03:09<00:00, 25.80it/s]\n",
      "100%|██████████| 700/700 [00:31<00:00, 22.56it/s]\n",
      "100%|██████████| 1400/1400 [01:09<00:00, 20.12it/s]\n"
     ]
    }
   ],
   "source": [
    "subesco = df[df['dataset'] == 'subesco']\n",
    "\n",
    "train_aug = subesco[(subesco['split'] == 'train') | (subesco['split'] == 'augment')]\n",
    "train = subesco[subesco['split'] == 'train']\n",
    "val = subesco[subesco['split'] == 'val']\n",
    "test = subesco[subesco['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/subesco/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/subesco/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/subesco/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/subesco/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6154/6154 [04:46<00:00, 21.47it/s]\n",
      "100%|██████████| 1026/1026 [00:33<00:00, 30.76it/s]\n",
      "100%|██████████| 147/147 [00:05<00:00, 28.45it/s]\n",
      "100%|██████████| 294/294 [00:10<00:00, 29.38it/s]\n"
     ]
    }
   ],
   "source": [
    "bser = df[df['dataset'] == 'bser']\n",
    "\n",
    "train_aug = bser[(bser['split'] == 'train') | (bser['split'] == 'augment')]\n",
    "train = bser[bser['split'] == 'train']\n",
    "val = bser[bser['split'] == 'val']\n",
    "test = bser[bser['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/bser/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/bser/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/bser/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/bser/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51051/51051 [44:15<00:00, 19.23it/s] \n",
      "100%|██████████| 8512/8512 [05:41<00:00, 24.91it/s]\n",
      "100%|██████████| 1217/1217 [00:49<00:00, 24.41it/s]\n",
      "100%|██████████| 2433/2433 [01:50<00:00, 22.09it/s]\n"
     ]
    }
   ],
   "source": [
    "all_en = df[df['language'] == 'en']\n",
    "\n",
    "train_aug = all_en[(all_en['split'] == 'train') | (all_en['split'] == 'augment')]\n",
    "train = all_en[all_en['split'] == 'train']\n",
    "val = all_en[all_en['split'] == 'val']\n",
    "test = all_en[all_en['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/all_en/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/all_en/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/all_en/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/all_en/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35540/35540 [30:39<00:00, 19.32it/s]\n",
      "100%|██████████| 5926/5926 [03:45<00:00, 26.30it/s]\n",
      "100%|██████████| 847/847 [00:36<00:00, 23.24it/s]\n",
      "100%|██████████| 1694/1694 [01:17<00:00, 21.93it/s]\n"
     ]
    }
   ],
   "source": [
    "all_bn = df[df['language'] == 'bn']\n",
    "\n",
    "train_aug = all_bn[(all_bn['split'] == 'train') | (all_bn['split'] == 'augment')]\n",
    "train = all_bn[all_bn['split'] == 'train']\n",
    "val = all_bn[all_bn['split'] == 'val']\n",
    "test = all_bn[all_bn['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/all_bn/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/all_bn/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/all_bn/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/all_bn/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86591/86591 [1:06:43<00:00, 21.63it/s]\n",
      "100%|██████████| 14438/14438 [09:14<00:00, 26.03it/s]\n",
      "100%|██████████| 2064/2064 [01:28<00:00, 23.38it/s]\n",
      "100%|██████████| 4127/4127 [03:07<00:00, 22.03it/s]\n"
     ]
    }
   ],
   "source": [
    "all = df\n",
    "\n",
    "train_aug = all[(all['split'] == 'train') | (all['split'] == 'augment')]\n",
    "train = all[all['split'] == 'train']\n",
    "val = all[all['split'] == 'val']\n",
    "test = all[all['split'] == 'test']\n",
    "\n",
    "save_embeddings(train_aug, f'./features/{folder_name}/all/', 'train_aug')\n",
    "save_embeddings(train, f'./features/{folder_name}/all/', 'train')\n",
    "save_embeddings(val, f'./features/{folder_name}/all/', 'val')\n",
    "save_embeddings(test, f'./features/{folder_name}/all/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'./features/{folder_name}/all/train_X.npy', allow_pickle=True)\n",
    "y = np.load(f'./features/{folder_name}/all/train_y.npy', allow_pickle=True)\n",
    "\n",
    "# a = np.load(f'./features/{folder_name}/all/val_X.npy', allow_pickle=True)\n",
    "# b = np.load(f'./features/{folder_name}/all/val_y.npy', allow_pickle=True)\n",
    "\n",
    "# X = np.concatenate((X, a), axis=0)\n",
    "# y = np.concatenate((y, b), axis=0)\n",
    "\n",
    "# a = np.load(f'./features/{folder_name}/all/test_X.npy', allow_pickle=True)\n",
    "# b = np.load(f'./features/{folder_name}/all/test_y.npy', allow_pickle=True)\n",
    "\n",
    "# X = np.concatenate((X, a), axis=0)\n",
    "# y = np.concatenate((y, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24972, 128), (24972,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'disgust'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'angry' b'disgust' b'fear' b'happy' b'neutral' b'sad' b'surprise'] [3315 4083 3552 3462 3922 4518 2120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.10/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "unique_items, counts = np.unique(y, return_counts=True)\n",
    "print(unique_items, counts)\n",
    "\n",
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'angry': 1.076147382029735,\n",
       " b'disgust': 0.8737273013540464,\n",
       " b'fear': 1.0043436293436294,\n",
       " b'happy': 1.03045308244615,\n",
       " b'neutral': 0.9095942303489474,\n",
       " b'sad': 0.78960349079871,\n",
       " b'surprise': 1.6827493261455526}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = dict(zip(np.unique(y), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "def plot_embeddings(df, name):\n",
    "\n",
    "    if df['Emotion'].nunique() == 6:\n",
    "        classes = CLASSES6\n",
    "    else:\n",
    "        classes = CLASSES7\n",
    "\n",
    "    fig, axs = plt.subplots(2, ceil(len(classes) / 2), figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .3, wspace=.3)\n",
    "    fig.suptitle(f'{name} VGGish Embeddings')\n",
    "    fig.tight_layout()\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        emb = get_embeddings(df[df['Emotion'] == classes[i]]['File_Path'].iloc[0], df[df['Emotion'] == classes[i]]['Emotion'].iloc[0])\n",
    "        axs[i].plot(emb[0][0])\n",
    "        # axs[i].imshow(emb[0].numpy(), aspect='auto', interpolation='nearest', origin='lower', cmap='jet')\n",
    "        axs[i].set_title(classes[i])\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(tess, 'TESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(savee, 'SAVEE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(ravdess, 'RAVDESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(crema, 'CREMA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
