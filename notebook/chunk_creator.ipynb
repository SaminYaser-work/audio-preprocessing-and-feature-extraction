{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.effects import normalize\n",
    "from vscode_audio import Audio\n",
    "from IPython.display import Audio as ipAudio\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 16000\n",
    "TOP_DB = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiosegment_to_librosawav(audiosegment):    \n",
    "    channel_sounds = audiosegment.split_to_mono()\n",
    "    samples = [s.get_array_of_samples() for s in channel_sounds]\n",
    "\n",
    "    fp_arr = np.array(samples).T.astype(np.float32)\n",
    "    fp_arr /= np.iinfo(samples[0].typecode).max\n",
    "    fp_arr = fp_arr.reshape(-1)\n",
    "\n",
    "    return fp_arr\n",
    "\n",
    "\n",
    "def librosa_to_audiosegment(filename):\n",
    "    y, sr = lr.load(filename, sr=RATE)\n",
    "    y, _ = lr.effects.trim(y, top_db=TOP_DB) # trim leading and trailing silence\n",
    "    y = nr.reduce_noise(y, sr=sr) # noise reduction\n",
    "    # convert from float to uint16\n",
    "    y = np.array(y * (1<<15), dtype=np.int16)\n",
    "    audio_segment = AudioSegment(\n",
    "        y.tobytes(), \n",
    "        frame_rate=sr,\n",
    "        sample_width=y.dtype.itemsize, \n",
    "        channels=1\n",
    "    )\n",
    "    return audio_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>sound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>../Datasets/Ravdess/Actor_08/03-01-02-01-01-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>../Datasets/Ravdess/Actor_08/03-01-04-02-02-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>../Datasets/Ravdess/Actor_08/03-01-02-01-02-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>../Datasets/Ravdess/Actor_08/03-01-03-01-02-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>../Datasets/Ravdess/Actor_08/03-01-06-01-02-02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                              sound\n",
       "0  neutral  ../Datasets/Ravdess/Actor_08/03-01-02-01-01-01...\n",
       "1      sad  ../Datasets/Ravdess/Actor_08/03-01-04-02-02-02...\n",
       "2  neutral  ../Datasets/Ravdess/Actor_08/03-01-02-01-02-01...\n",
       "3    happy  ../Datasets/Ravdess/Actor_08/03-01-03-01-02-01...\n",
       "4     fear  ../Datasets/Ravdess/Actor_08/03-01-06-01-02-02..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ravdess_Path='../Datasets/Ravdess/'\n",
    "ravdess=[]\n",
    "for directory in os.listdir(Ravdess_Path):\n",
    "    actors=os.listdir(os.path.join(Ravdess_Path,directory))\n",
    "    for wav in actors:\n",
    "        emotion=wav.partition('.wav')[0].split('-')\n",
    "        emotion_number=int(emotion[2])\n",
    "        ravdess.append((emotion_number,os.path.join(Ravdess_Path,directory,wav)))\n",
    "Ravdess_df=pd.DataFrame.from_dict(ravdess)\n",
    "Ravdess_df.rename(columns={0:'emotion',1:'sound'},inplace=True)\n",
    "Ravdess_df['emotion'].replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'},inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ds = 'all_en'\n",
    "# # feat_ex_technique = 'formants'\n",
    "\n",
    "# # Defines ratios, w.r.t. whole dataset.\n",
    "# ratio_train = 0.7\n",
    "# ratio_val = 0.15\n",
    "# ratio_test = 0.15\n",
    "\n",
    "# def get_splits(d):\n",
    "#     # Produces test split.\n",
    "#     remaining, test = train_test_split(\n",
    "#         d, test_size=ratio_test, stratify=d['emotion'])\n",
    "\n",
    "#     # Adjusts val ratio, w.r.t. remaining dataset.\n",
    "#     ratio_remaining = 1 - ratio_test\n",
    "#     ratio_val_adjusted = ratio_val / ratio_remaining\n",
    "\n",
    "#     # Produces train and val splits.\n",
    "#     train, val = train_test_split(\n",
    "#         remaining, test_size=ratio_val_adjusted, stratify=remaining['emotion'])\n",
    "        \n",
    "#     return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 2), (216, 2), (216, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, val, test = get_splits(Ravdess_df)\n",
    "# train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../Datasets/custom/'\n",
    "\n",
    "def save_as_chunks(df: pd.DataFrame):\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        og = librosa_to_audiosegment(row['sound'])\n",
    "        norm = normalize(og, headroom=5.0)\n",
    "        chunks = split_on_silence(norm, min_silence_len=20, silence_thresh=norm.dBFS-16)\n",
    "        emo = row['emotion']\n",
    "        \n",
    "        for j, chunk in enumerate(chunks):\n",
    "            chunk.export(f'{output_folder}{emo}_{i}_{j}.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [03:05<00:00,  7.77it/s]\n"
     ]
    }
   ],
   "source": [
    "save_as_chunks(Ravdess_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:36<00:00,  5.95it/s]\n",
      "100%|██████████| 216/216 [00:33<00:00,  6.36it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
